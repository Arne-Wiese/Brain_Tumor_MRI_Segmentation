{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e4cdfcf",
   "metadata": {},
   "source": [
    "# 2D Convolutional Network for Brain Tumor Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4866caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57e802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural imaging\n",
    "import nibabel as nib\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import utils.hpc\n",
    "if not utils.hpc.running_on_hpc():\n",
    "    import kagglehub\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.datasets import BraTSDataset_2D\n",
    "from utils.models import UNet\n",
    "from utils.losses import CombinedLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48424aa",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10bf2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "NUM_EPOCHS = 10\n",
    "MODEL_NAME = 'v1_3d' # change for each model!!\n",
    "MODEL_SAVE_PATH = f'checkpoints/{MODEL_NAME}.pth'\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 1\n",
    "SLICE_RANGE = (22, 122)\n",
    "N_SLICES = 5 # for 2.5D model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84882bbe",
   "metadata": {},
   "source": [
    "## Download the brats dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a77ef0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if utils.hpc.running_on_hpc():\n",
    "    TRAIN_DATASET_PATH = utils.hpc.load_dataset_into_ram()\n",
    "else:\n",
    "    # Download latest version\n",
    "    path = kagglehub.dataset_download(\"awsaf49/brats20-dataset-training-validation\")\n",
    "    print(\"Path to dataset files:\", path)\n",
    "    TRAIN_DATASET_PATH = path + '/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99ba35b",
   "metadata": {},
   "source": [
    "## Create the dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abc7f6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 258 patients\n",
      "Val: 55 patients\n",
      "Test: 56 patients\n"
     ]
    }
   ],
   "source": [
    "all_patients = sorted([d for d in os.listdir(TRAIN_DATASET_PATH)\n",
    "                      if os.path.isdir(os.path.join(TRAIN_DATASET_PATH, d))])\n",
    "\n",
    "# First split: 70% train, 30% temp\n",
    "train_patients, temp_patients = train_test_split(\n",
    "    all_patients, test_size=0.30, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: split temp into 50/50 (15% val, 15% test of original)\n",
    "val_patients, test_patients = train_test_split(\n",
    "    temp_patients, test_size=0.50, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_patients)} patients\")\n",
    "print(f\"Val: {len(val_patients)} patients\")\n",
    "print(f\"Test: {len(test_patients)} patients\")\n",
    "\n",
    "\n",
    "# Create 2.5D dataset\n",
    "train_dataset = BraTSDataset_2D(train_patients, TRAIN_DATASET_PATH, slice_range=SLICE_RANGE)\n",
    "val_dataset = BraTSDataset_2D(val_patients, TRAIN_DATASET_PATH, slice_range=SLICE_RANGE)\n",
    "test_dataset = BraTSDataset_2D(test_patients, TRAIN_DATASET_PATH, slice_range=SLICE_RANGE)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44fa1dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device - prioritize MPS for Mac, then CUDA, then CPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c942b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 31044292 parameters\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = UNet(n_channels=4, n_classes=4).to(device)\n",
    "\n",
    "# Loss function - CrossEntropyLoss for multi-class segmentation\n",
    "criterion = CombinedLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9cbb9f",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55483aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_history_fn = lambda history : utils.visualizations.history_to_json(\n",
    "    history=history,\n",
    "    model_name=MODEL_NAME,\n",
    "    save_dir='logs',\n",
    "    # Configuration parameters\n",
    "    batch_size=BATCH_SIZE,\n",
    "    slice_range=SLICE_RANGE,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    optimizer='Adam',\n",
    "    loss_function='CombinedLoss',\n",
    "    model_type='UNet',\n",
    "    model_parameters=sum(p.numel() for p in model.parameters()),\n",
    "    dataset_type='2D',\n",
    "    early_stopping_patience=10,\n",
    "    augmentations=False,\n",
    "    device=str(device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c967e592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 35/404 [01:48<18:50,  3.06s/it, loss=0.9705]"
     ]
    }
   ],
   "source": [
    "# Run training loop\n",
    "history = utils.training.train_loop(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    device=device,\n",
    "    primary_metric='dice',\n",
    "    scheduler=scheduler,\n",
    "    save_best_model=True,\n",
    "    model_save_path=MODEL_SAVE_PATH,\n",
    "    early_stopping_patience=10,\n",
    "    save_history_fn=save_history_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6dad9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_detailed_training_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_detailed_training_history\u001b[49m(\n\u001b[1;32m      2\u001b[0m     history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m      3\u001b[0m     save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124massets/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/detailed_training_history.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_detailed_training_history' is not defined"
     ]
    }
   ],
   "source": [
    "utils.visualizations.plot_detailed_training_history(\n",
    "    history=history,\n",
    "    save_path=f'assets/{MODEL_NAME}/detailed_training_history.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb44e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved training history to logs/v1_2d_history.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'logs/v1_2d_history.json'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save history to JSON\n",
    "utils.visualizations.history_to_json(\n",
    "    history=history,\n",
    "    model_name=MODEL_NAME,\n",
    "    save_dir='logs',\n",
    "    # Configuration parameters\n",
    "    batch_size=BATCH_SIZE,\n",
    "    slice_range=SLICE_RANGE,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    optimizer='Adam',\n",
    "    loss_function='CombinedLoss',\n",
    "    model_type='UNet',\n",
    "    model_parameters=sum(p.numel() for p in model.parameters()),\n",
    "    dataset_type='2D',  # oder '2.5D'\n",
    "    early_stopping_patience=10,\n",
    "    augmentations=False,\n",
    "    device=str(device),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
